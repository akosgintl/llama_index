# Querying

Querying is the most important part of your LLM application. To learn more about getting a final product that you can deploy, check out the [query engine](/python/framework/module_guides/deploying/query_engine/index), [chat engine](/python/framework/module_guides/deploying/chat_engines/index).

If you wish to combine advanced reasoning with tool use, check out our [agents](/python/framework/module_guides/deploying/agents/index) guide.

## Query Workflows

You can create workflows for querying with ease, using our event-driven `Workflow` interface. Check out our [workflow guide](/python/framework/module_guides/workflow/index) for more details.

Otherwise check out how to use our query modules as standalone components ðŸ‘‡.

## Query Modules

- [Query Engines](/python/framework/module_guides/deploying/query_engine/index)
- [Chat Engines](/python/framework/module_guides/deploying/chat_engines/index)
- [Agents](/python/framework/module_guides/deploying/agents/index)
- [Retrievers](/python/framework/module_guides/querying/retriever/index)
- [Response Synthesizers](/python/framework/module_guides/querying/response_synthesizers/index)
- [Routers](/python/framework/module_guides/querying/router/index)
- [Node Postprocessors](/python/framework/module_guides/querying/node_postprocessors/index)
- [Structured Outputs](/python/framework/module_guides/querying/structured_outputs/index)
